{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "dedcf69bcf0e412bb464b5eff17f23ff",
        "deepnote_cell_type": "markdown",
        "id": "VEYe67K6E6j0"
      },
      "source": [
        "## **Grasp Candidate Sampling**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "d758df06d75c4ee0be672ea194827b76",
        "deepnote_cell_type": "code",
        "id": "v5OrhpSmxkGH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pydrake.all import (\n",
        "    AddMultibodyPlantSceneGraph,\n",
        "    Box,\n",
        "    DiagramBuilder,\n",
        "    MeshcatVisualizer,\n",
        "    MeshcatVisualizerParams,\n",
        "    Parser,\n",
        "    PointCloud,\n",
        "    Rgba,\n",
        "    RigidTransform,\n",
        "    RotationMatrix,\n",
        "    StartMeshcat\n",
        ")\n",
        "from scipy.spatial import KDTree\n",
        "\n",
        "from manipulation import running_as_notebook\n",
        "from manipulation.meshcat_utils import AddMeshcatTriad\n",
        "from manipulation.mustard_depth_camera_example import MustardPointCloud\n",
        "from manipulation.scenarios import AddMultibodyTriad\n",
        "from manipulation.utils import ConfigureParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_id": "40013117b6e046488c7c26e5e959b22b",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:drake:Meshcat listening for connections at http://localhost:7001\n"
          ]
        }
      ],
      "source": [
        "# Start the visualizer.\n",
        "meshcat = StartMeshcat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cell_id": "2e4b76152d494af28b5024ab2a97e53f",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "source": [
        "# Basic setup\n",
        "pcd = MustardPointCloud(normals=True, down_sample=False)\n",
        "\n",
        "meshcat.SetProperty(\"/Background\", \"visible\", False)\n",
        "meshcat.SetObject(\"cloud\", pcd, point_size=0.001)\n",
        "\n",
        "\n",
        "def setup_grasp_diagram(draw_frames=True):\n",
        "    builder = DiagramBuilder()\n",
        "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.001)\n",
        "    parser = Parser(plant)\n",
        "    ConfigureParser(parser)\n",
        "    parser.AddModelsFromUrl(\"package://manipulation/schunk_wsg_50_welded_fingers.sdf\")\n",
        "    if draw_frames:\n",
        "        AddMultibodyTriad(plant.GetFrameByName(\"body\"), scene_graph)\n",
        "    plant.Finalize()\n",
        "\n",
        "    MeshcatVisualizer.AddToBuilder(builder, scene_graph, meshcat)\n",
        "    diagram = builder.Build()\n",
        "    context = diagram.CreateDefaultContext()\n",
        "\n",
        "    return plant, scene_graph, diagram, context\n",
        "\n",
        "\n",
        "def draw_grasp_candidate(X_G, prefix=\"gripper\", draw_frames=True, refresh=False):\n",
        "    if refresh:\n",
        "        meshcat.Delete()\n",
        "    builder = DiagramBuilder()\n",
        "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.001)\n",
        "    parser = Parser(plant)\n",
        "    ConfigureParser(parser)\n",
        "    gripper = parser.AddModelsFromUrl(\n",
        "        \"package://manipulation/schunk_wsg_50_welded_fingers.sdf\"\n",
        "    )\n",
        "    plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"body\"), X_G)\n",
        "    if draw_frames:\n",
        "        AddMultibodyTriad(plant.GetFrameByName(\"body\"), scene_graph)\n",
        "    plant.Finalize()\n",
        "\n",
        "    params = MeshcatVisualizerParams()\n",
        "    params.prefix = prefix\n",
        "    meshcat_vis = MeshcatVisualizer.AddToBuilder(builder, scene_graph, meshcat, params)\n",
        "    diagram = builder.Build()\n",
        "    context = diagram.CreateDefaultContext()\n",
        "    diagram.ForcedPublish(context)\n",
        "\n",
        "\n",
        "def compute_sdf(pcd, X_G, visualize=False):\n",
        "    plant, scene_graph, diagram, context = setup_grasp_diagram()\n",
        "    plant_context = plant.GetMyContextFromRoot(context)\n",
        "    scene_graph_context = scene_graph.GetMyContextFromRoot(context)\n",
        "    plant.SetFreeBodyPose(plant_context, plant.GetBodyByName(\"body\"), X_G)\n",
        "\n",
        "    if visualize:\n",
        "        diagram.ForcedPublish(context)\n",
        "\n",
        "    query_object = scene_graph.get_query_output_port().Eval(scene_graph_context)\n",
        "\n",
        "    pcd_sdf = np.inf\n",
        "    for pt in pcd.xyzs().T:\n",
        "        distances = query_object.ComputeSignedDistanceToPoint(pt)\n",
        "        for body_index in range(len(distances)):\n",
        "            distance = distances[body_index].distance\n",
        "            if distance < pcd_sdf:\n",
        "                pcd_sdf = distance\n",
        "\n",
        "    return pcd_sdf\n",
        "\n",
        "\n",
        "def check_collision(pcd, X_G, visualize=False):\n",
        "    sdf = compute_sdf(pcd, X_G, visualize)\n",
        "    return sdf > 0 # No collision if the signed distance is positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3b24d0adc75f49d29cda89eed9583557",
        "deepnote_cell_type": "markdown",
        "id": "ZUg7IbDmIyeo"
      },
      "source": [
        "## Grasp Candidate based on Local Curvature \n",
        "\n",
        "This is an implementation-heavy assignment, where we will implement a variation of the grasp candidate sampling algorithm on [this paper](https://arxiv.org/pdf/1706.09911.pdf). from 2017. Parts of the [library](https://github.com/atenpas/gpg) based on the paper, which the authors have named \"Grasp Pose Generator\" (GPG), is used in real grasp selection systems including the one being run at Toyota Research Institute. \n",
        "\n",
        "As opposed to sampling candidate grasp poses using the \"antipodal heuristic\", this sampling algorithm uses a heuristic based on the local curvature. This heursitic can work quite well especially for smoother / symmetrical objects which has relatively consistent curvature characteristics. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "aaa1b6c1d8ac4ac2992d0538e7642f6d",
        "deepnote_cell_type": "markdown",
        "id": "1PAeSQRiHRNi"
      },
      "source": [
        "## Computing the Darboux Frame\n",
        "\n",
        "First, let's work on formalizing our notion of a \"local curvature\" by bringing up the [**Darboux Frame**](https://en.wikipedia.org/wiki/Darboux_frame) from differential geometry. It has a fancy French name (after its creator), but the concept is quite simple.\n",
        "\n",
        "Given a point $p\\in\\mathbb{R}^3$ on a differentiable surface $\\mathcal{S}\\subset\\mathbb{R}^3$, we've seen that we can compute the normal vector at point $p$. Let's denote this vector as $n(p)$. \n",
        "\n",
        "The Darboux frame first aligns the $y$-axis with the inward normal vector, and aligns the $x$ and $z$ axis with principal axii of the tangent surface given the curvature. We will define the axis as \n",
        "- x-axis: aligned with the major axis of curvature at point $p$.\n",
        "- y-axis: aligned with the inward normal vector at point $p$.\n",
        "- z-axis: aligned with the minor axis of curvature at point $p$. \n",
        "\n",
        "Where major axis of curvature has a smaller radius of curvature compared to the minor axis. The below figure might clear things up. \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/RussTedrake/manipulation/master/book/figures/exercises/darboux_frame.png\" width=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "7c473a00b429464f9345422cd8cd2329",
        "deepnote_cell_type": "markdown",
        "id": "J5WdmM8hQkQ7"
      },
      "source": [
        "Below, your job is to compute the RigidTransform from the world to the Darboux frame of a specific point on the pointcloud. \n",
        "\n",
        "Here is a simple outline of the algorithm that we've seen in class:\n",
        "1. Compute the set of points $\\mathcal{S}$ around the given point using [`kdtree.query`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.query.html), with `ball_radius` as the distance upper bound.  \n",
        "2. Compute the $3\\times3$ matrix with sum of outer-products of the normal vectors. \n",
        "$$\\mathbf{N}=\\sum_{p\\in\\mathcal{S}} n(p)n^T(p)$$\n",
        "3. Run eigen decomposition and get the eigenvectors using `np.linalg.eig`. Denote the eigen vectors as $[v_1, v_2, v_3]$, in order of decreasing corresponding eigenvalues. Convince yourself that:\n",
        "- $v_1$ is the normal vector,\n",
        "- $v_2$ is the major tangent vector, \n",
        "- $v_3$ is the minor tangent vector. \n",
        "Note that `np.linalg.eig` does **not** necessarily return the eigenvectors in the correct order. (The function `np.argsort` may come in handy.)\n",
        "4. If $v_1$ is heading outwards (same direction as $n(p)$), negate $v_1$. (You can check this using the dot product.)\n",
        "5. Using $v_1,v_2,v_3$, construct the Rotation matrix by horizontally stacking the vertical vectors: $\\mathbf{R} = [v_2 | v_1 | v_3]$\n",
        "6. If the rotation is improper, negate $v_2$. (You can check this by checking the sign of the determinant.)\n",
        "7. Return a `RigidTransform` that has the rotation set as defined in the figure above, and translation defined at the desired point.\n",
        "\n",
        "The [textbook example on normal estimation](https://manipulation.csail.mit.edu/clutter.html#normal_estimation) may be useful to reference in this problem.\n",
        "\n",
        "NOTE: Convince yourself of the following: if you knew the orthonormal basis vectors of a frame ${}^W[i,j,k]$, then the Rotation matrix of of that frame with respect to the world ${}^W\\mathbf{R}^F$ can be computed by horizontally stacking the vertical vectors ($[i|j|k]$). Why would this be? (This doesn't necessarily mean the eigenvector matrix is always a rotation matrix due to improper rotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cell_id": "be24fab911204cacacc23bf44b8a3a82",
        "deepnote_cell_type": "code",
        "id": "WRuwFwcuTQtw"
      },
      "outputs": [],
      "source": [
        "def compute_darboux_frame(index, pcd, kdtree, ball_radius=0.002, max_nn=50):\n",
        "    \"\"\"\n",
        "    Given a index of the pointcloud, return a RigidTransform from world to the\n",
        "    Darboux frame at that point.\n",
        "    Args:\n",
        "    - index (int): index of the pointcloud.\n",
        "    - pcd (PointCloud object): pointcloud of the object.\n",
        "    - kdtree (scipy.spatial.KDTree object): kd tree to use for nn search.\n",
        "    - ball_radius (float): ball_radius used for nearest-neighbors search\n",
        "    - max_nn (int): maximum number of points considered in nearest-neighbors search.\n",
        "    \"\"\"\n",
        "    points = pcd.xyzs()  # 3xN np array of points\n",
        "    normals = pcd.normals()  # 3xN np array of normals (ijk)\n",
        "\n",
        "    poi = points[:, index]\n",
        "\n",
        "    # 1) Compute the set of points $\\mathcal{S}$ around the given point using [`kdtree.query`]\n",
        "    (distances, indices) = kdtree.query(\n",
        "        poi, k=max_nn, distance_upper_bound=ball_radius\n",
        "    )\n",
        "    \n",
        "    # 2) Compute the 3x3 matrix with sum of outer-products of the normal vectors\n",
        "    # the below code is suspect\n",
        "    N = np.zeros((3, 3))\n",
        "    for i in range(max_nn):\n",
        "        if indices[i] == points.shape[1]:\n",
        "            continue\n",
        "        n = normals[:, indices[i]]\n",
        "        N += np.outer(n, n)\n",
        "\n",
        "    # 3) Run eigenvalue decomposition on the matrix and get the eigenvectors using `np.linalg.eig`. \n",
        "    # Denote the eigen vectors as $[v_1, v_2, v_3]$, in order of decreasing corresponding eigenvalues.\n",
        "    w, V = np.linalg.eigh(N)\n",
        "\n",
        "    # 3a) Manipulate the eigenvectors to put in the correct order (see above)\n",
        "    w = np.fliplr([w])[0]\n",
        "    V = np.fliplr(V)\n",
        "    # now, v_1 is the normal vector, v_2 is the major axis, and v_3 is the minor axis\n",
        "\n",
        "    # 4) If $v_1$ is heading outwards (same direction as $n(p)$), negate $v_1$. (You can check this using the dot product.)\n",
        "    if normals[:, index].dot(V[:, 0]) > 0:\n",
        "        V[:, 0] *= -1\n",
        "\n",
        "    # 5) Using $v_1,v_2,v_3$, construct the Rotation matrix by horizontally stacking the vertical vectors: $\\mathbf{R} = [v_2 | v_1 | v_3]$\n",
        "    R = np.array([V[:,1], V[:,0], V[:,2]]).T\n",
        "\n",
        "    # 6) If the rotation is improper, negate $v_2$. (You can check this by checking the sign of the determinant.)\n",
        "    if np.linalg.det(R) < 0:\n",
        "        R[:, 0] *= -1\n",
        "\n",
        "    # 7) Return a `RigidTransform` that has the rotation set as defined in the figure above, and translation defined at the desired point.\n",
        "    X_WF = RigidTransform(R=RotationMatrix(R),p=poi.T)  # modify here.\n",
        "\n",
        "    return X_WF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a0f98e6869df463383647315d47f5a95",
        "deepnote_cell_type": "markdown",
        "id": "O3Nmr31JUZPB"
      },
      "source": [
        "You can check your work by running the cell below and looking at the frame visualization in Meshcat. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cell_id": "82f7c155265b4f0db015519f46a4f407",
        "deepnote_cell_type": "code",
        "id": "TcNpDwGiZw1n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.97097954 -0.23015329 -0.06502452  0.00317484]\n",
            " [ 0.23849003 -0.95215025 -0.19113452  0.0091589 ]\n",
            " [-0.01792288 -0.20109541  0.97940768  0.18613544]\n",
            " [ 0.          0.          0.          1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# 151, 11121 are pretty good verifiers of the implementation.\n",
        "index = 151\n",
        "meshcat.Delete()\n",
        "\n",
        "# Build KD tree.\n",
        "kdtree = KDTree(pcd.xyzs().T)\n",
        "X_WP = compute_darboux_frame(index, pcd, kdtree)\n",
        "print(X_WP.GetAsMatrix4())\n",
        "meshcat.SetObject(\"cloud\", pcd)\n",
        "AddMeshcatTriad(meshcat, \"frame\", length=0.025, radius=0.001, X_PT=X_WP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "1680a2dde31d456f81448bcd2169ba78",
        "deepnote_cell_type": "markdown",
        "id": "HrdDJyHzU4W_"
      },
      "source": [
        "## Collision Line Search \n",
        "\n",
        "Now we wish to align our gripper frame with the Darboux frame that we found, but naively doing it will result in collision / being too far from the object.\n",
        "\n",
        "An important heuristic that is used in the GPG work is that grasps are more stable when contact area is maximized. For that, we would need the gripper to be as inwards as possible towards the object but avoid collisions.\n",
        "\n",
        "To implement this, we will use a line search along a grid along the y-axis, and find the **maximum** value of $y$ (remember that our $y$ is towards the inwards normal) that results in no-collision. \n",
        "\n",
        "We've given you the grid you should search over, and the function `distance=compute_sdf(pcd, X_WG)` that will return the signed distance function between the set of pointclouds, and the gripper, given the transform `X_WG`. You are required to use this to detect the presence of collisions. \n",
        "\n",
        "Finally, if there is no value of $y$ that results in no collisions, you should return `np.nan` for the signed distance, and `None` for the rigid transform. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cell_id": "f5954b2b65434a4985b8cfbbf2de162f",
        "deepnote_cell_type": "code",
        "id": "tUgWtIoDW-x2"
      },
      "outputs": [],
      "source": [
        "# Compute static rotation between the frame and the gripper.\n",
        "\n",
        "def find_minimum_distance(pcd, X_WG):\n",
        "    \"\"\"\n",
        "    By doing line search, compute the maximum allowable distance along the y axis before penetration.\n",
        "    Return the maximum distance, as well as the new transform.\n",
        "    Args:\n",
        "      - pcd (PointCloud object): pointcloud of the object.\n",
        "      - X_WG (Drake RigidTransform object): RigidTransform. You can expect this to be the return from compute_darboux_frame.\n",
        "    Return:\n",
        "      - Tuple (signed_distance, X_WGnew) where\n",
        "      - signed_distance (float): signed distance between gripper and object pointcloud at X_WGnew.\n",
        "      - X_WGnew: New rigid transform that moves X_WG along the y axis while maximizing the y-translation subject to no collision.\n",
        "      If there is no value of y that results in no collisions, return (np.nan, None).\n",
        "    \"\"\"\n",
        "    y_grid = np.linspace(-0.05, 0.05, 10)  # do not modify\n",
        "\n",
        "    # init in case we can't find anything w/o collision\n",
        "    signed_distance = np.nan\n",
        "    X_WGnew = None\n",
        "\n",
        "    for y in y_grid:\n",
        "        test_X_WG = X_WG.multiply(RigidTransform(p=[0, y, 0]))\n",
        "        if check_collision(pcd, test_X_WG):  # no collision\n",
        "            signed_distance = compute_sdf(pcd, test_X_WG)\n",
        "            X_WGnew = test_X_WG\n",
        "\n",
        "\n",
        "    return signed_distance, X_WGnew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "658e5b4299eb4829b72f3a6cd252c0b2",
        "deepnote_cell_type": "markdown",
        "id": "s3E771RFXO7N"
      },
      "source": [
        "You can check your work below by running the cell below. If the visualization results in a collision, or the gripper is excessively far from the object, your implementation is probably wrong. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cell_id": "b0cd7134c49e41caaeb882117df73fd1",
        "deepnote_cell_type": "code",
        "id": "NvPNcEzpWqzt"
      },
      "outputs": [],
      "source": [
        "meshcat.Delete()\n",
        "meshcat.SetObject(\"cloud\", pcd, point_size=0.001)\n",
        "AddMeshcatTriad(meshcat, \"frame\", length=0.025, radius=0.001, X_PT=X_WP)\n",
        "shortest_distance, X_WGnew = find_minimum_distance(pcd, X_WP)\n",
        "draw_grasp_candidate(X_WGnew, refresh=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f5ac55177eb549a1927b88894c349e0d",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "## Nonempty Grasp \n",
        "\n",
        "Let's add one more heuristic: when we close the gripper, we don't want what is in between the two fingers to be an empty region. That would make our robot look not very smart! \n",
        "\n",
        "There is a simple way to check this: let's define a volumetric region swept by the gripper's closing trajectory, and call it $\\mathcal{B}(^{W}X^{G})$. We will also call the gripper body (when fully open) as the set $\\mathcal{C}(^{W}X^G)$. If there are no object pointclouds within the set $\\mathcal{B}(^{W}X^{G})$, we can simply discard it. \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/RussTedrake/manipulation/master/book/figures/exercises/closing_plane.png\" width=\"800\">\n",
        "\n",
        "You're probably thinking - how do I do a rigid transform on a set? Generally it's doable if the transform is affine, the set is polytopic, etc., but there is an easier trick - we just transform all the pointclouds to the gripper frame $G$! \n",
        "\n",
        "The function below follows these steps:\n",
        "  1. Transform the pointcloud points `pcd` from world frame to gripper frame.\n",
        "  2. For each point, check if it is within the bounding box we have provided.\n",
        "  3. If there is a point inside the set, return True. If not, return false. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "cell_id": "c2fa3918a95f4d0787fb0717c275108f",
        "deepnote_cell_type": "code",
        "id": "8aUP5vcLt-Cm"
      },
      "outputs": [],
      "source": [
        "def check_nonempty(pcd, X_WG, visualize=False):\n",
        "    \"\"\"\n",
        "    Check if the \"closing region\" of the gripper is nonempty by transforming the pointclouds to gripper coordinates.\n",
        "    Args:\n",
        "      - pcd (PointCloud object): pointcloud of the object.\n",
        "      - X_WG (Drake RigidTransform): transform of the gripper.\n",
        "    Return:\n",
        "      - is_nonempty (boolean): boolean set to True if there is a point within the cropped region.\n",
        "    \"\"\"\n",
        "    pcd_W_np = pcd.xyzs()\n",
        "\n",
        "    # Bounding box of the closing region written in the coordinate frame of the gripper body.\n",
        "    # Do not modify\n",
        "    crop_min = [-0.05, 0.1, -0.00625]\n",
        "    crop_max = [0.05, 0.1125, 0.00625]\n",
        "\n",
        "    # Transform the pointcloud to gripper frame.\n",
        "    X_GW = X_WG.inverse()\n",
        "    pcd_G_np = X_GW.multiply(pcd_W_np)\n",
        "\n",
        "    # Check if there are any points within the cropped region.\n",
        "    indices = np.all(\n",
        "        (\n",
        "            crop_min[0] <= pcd_G_np[0, :],\n",
        "            pcd_G_np[0, :] <= crop_max[0],\n",
        "            crop_min[1] <= pcd_G_np[1, :],\n",
        "            pcd_G_np[1, :] <= crop_max[1],\n",
        "            crop_min[2] <= pcd_G_np[2, :],\n",
        "            pcd_G_np[2, :] <= crop_max[2],\n",
        "        ),\n",
        "        axis=0,\n",
        "    )\n",
        "\n",
        "    is_nonempty = indices.any()\n",
        "\n",
        "    if visualize:\n",
        "        meshcat.Delete()\n",
        "        pcd_G = PointCloud(pcd)\n",
        "        pcd_G.mutable_xyzs()[:] = pcd_G_np\n",
        "\n",
        "        draw_grasp_candidate(RigidTransform())\n",
        "        meshcat.SetObject(\"cloud\", pcd_G)\n",
        "\n",
        "        box_length = np.array(crop_max) - np.array(crop_min)\n",
        "        box_center = (np.array(crop_max) + np.array(crop_min)) / 2.0\n",
        "        meshcat.SetObject(\n",
        "            \"closing_region\",\n",
        "            Box(box_length[0], box_length[1], box_length[2]),\n",
        "            Rgba(1, 0, 0, 0.3),\n",
        "        )\n",
        "        meshcat.SetTransform(\"closing_region\", RigidTransform(box_center))\n",
        "\n",
        "    return is_nonempty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d8cca7cd82864fea97117a140aa75d6e",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "The following cell demonstrates the functionality of `check_nonempty`, where we have visualized the pointclouds and $\\mathcal{B}({}^W X^G)$ from the gripper frame. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "cell_id": "b6eb47b2ddf4424496afc65de582e3f5",
        "deepnote_cell_type": "code",
        "id": "BBg0NCWd2qI8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lower and upper bounds of the closing region in gripper coordinates. Do not modify.\n",
        "check_nonempty(pcd, X_WGnew, visualize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "55a1fc890103462dbb0c0465d3926d65",
        "deepnote_cell_type": "markdown",
        "id": "dwGE2JDnXmY5"
      },
      "source": [
        "## Grasp Sampling Algorithm\n",
        "\n",
        "That was a lot of subcomponents, but we're finally onto the grand assembly. You will now generate `candidate_num` candidate grasps using everything we have written so far. The sampling algorithm goes as follows:\n",
        "\n",
        "1. Select a random point $p$ from the pointcloud (use `np.random.randint()`)\n",
        "2. Compute the Darboux frame ${}^WX^F(p)$ of the point $p$ using `compute_darboux_frame`. \n",
        "3. Randomly sample an $x$ direction translation $x\\in[x_{min},x_{max}]$, and a $z$ direction rotation $\\phi\\in[\\phi_{min},\\phi_{max}]$. Compute a grasp frame $T$ that has the relative transformation `X_FT=(RotateZ(phi),TranslateX(x))`. Convince yourself this makes the point $p$ stay in the \"closing plane\" (drawn in red) defined in the figure above. (NOTE: For ease of grading, make sure you compute the $x$ direction first with `np.random.rand()`, then compute the $\\phi$ direction with another call to `np.random.rand()`, not the other way around.) \n",
        "4. From the grasp frame $T$, translate along the $y$ axis such that the gripper is closest to the object without collision. Use `find_minimum_distance`, and call this frame $G$. Remember that `find_minimum_distance` can return `np.nan`. Skip the loop if this happens. \n",
        "5. If $G$ results in no collisions (see `check_collision`) and results in non-empty grasp (use `check_nonempty`), append it to the candidate list. If not, continue the loop until we have desired number of candidates. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "cell_id": "5c325b2beb6744e5ac90c31fdf8c3aad",
        "deepnote_cell_type": "code",
        "id": "LvKVHqv8fnq1"
      },
      "outputs": [],
      "source": [
        "def compute_candidate_grasps(pcd, candidate_num=10, random_seed=5):\n",
        "    \"\"\"\n",
        "    Compute candidate grasps.\n",
        "    Args:\n",
        "        - pcd (PointCloud object): pointcloud of the object.\n",
        "        - candidate_num (int) : number of desired candidates.\n",
        "        - random_seed (int) : seed for rng, used for grading.\n",
        "    Return:\n",
        "        - candidate_lst (list of drake RigidTransforms) : candidate list of grasps.\n",
        "    \"\"\"\n",
        "\n",
        "    # Do not modify.\n",
        "    x_min = -0.03\n",
        "    x_max = 0.03\n",
        "    phi_min = -np.pi / 3\n",
        "    phi_max = np.pi / 3\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # Build KD tree for the pointcloud.\n",
        "    kdtree = KDTree(pcd.xyzs().T)\n",
        "    ball_radius = 0.002\n",
        "\n",
        "    candidate_count = 0\n",
        "    candidate_lst = []  # list of candidates, given by RigidTransforms.\n",
        "\n",
        "    # Modify from here.\n",
        "\n",
        "    for i in range(candidate_num):\n",
        "        # select a point from the pointcloud\n",
        "        p_index = np.random.randint(0, pcd.xyzs().shape[1])\n",
        "        X_WP = compute_darboux_frame(p_index, pcd, kdtree, ball_radius=ball_radius)\n",
        "\n",
        "        x = np.random.uniform(x_min, x_max)\n",
        "        phi = np.random.uniform(phi_min, phi_max)\n",
        "\n",
        "        X_FT = RigidTransform(RotationMatrix.MakeZRotation(phi), [x, 0, 0])\n",
        "\n",
        "        (signed_distance, X_G) = find_minimum_distance(pcd, X_WP.multiply(X_FT))\n",
        "        if np.isnan(signed_distance):\n",
        "            continue\n",
        "\n",
        "        no_collision = check_collision(pcd, X_G)\n",
        "        not_empty = check_nonempty(pcd, X_G)\n",
        "\n",
        "        if no_collision and not_empty:\n",
        "            candidate_lst.append(X_G)\n",
        "            candidate_count += 1\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    return candidate_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9a1b08801f6f48d29c70b9d139de9626",
        "deepnote_cell_type": "markdown",
        "id": "dypaCKcOf9cn"
      },
      "source": [
        "You can check your implementation by running the cell below. Note that although we've only sampled 20 candidates, a lot of them look promising. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "cell_id": "927cca6b48804726ba1040481f9cb260",
        "deepnote_cell_type": "code",
        "id": "ItS9GtKaZ39w"
      },
      "outputs": [],
      "source": [
        "pcd_downsampled = pcd.VoxelizedDownSample(voxel_size=0.005)\n",
        "\n",
        "if running_as_notebook:\n",
        "    grasp_candidates = compute_candidate_grasps(\n",
        "        pcd_downsampled, candidate_num=3, random_seed=5\n",
        "    )\n",
        "\n",
        "    meshcat.Delete()\n",
        "    meshcat.SetObject(\"cloud\", pcd_downsampled)\n",
        "    for i in range(len(grasp_candidates)):\n",
        "        draw_grasp_candidate(\n",
        "            grasp_candidates[i], prefix=\"gripper\" + str(i), draw_frames=False\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4c12a52390ae408398bcacb622fda2ba",
        "deepnote_cell_type": "markdown",
        "id": "7jcCyk-q2U3L"
      },
      "source": [
        "## Note on Running Time\n",
        "\n",
        "You might be disappointed in how slowly this runs, but the same algorithm written in C++ with optimized libraries can run much faster. (I would expect around a 20 times speedup). \n",
        "\n",
        "But more fundamentally, it's important to note how trivially parallelizable the candidate sampling process is. With a parallelized and optimized implementation, hundreds of grasp candidates can be sampled in real time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8ed43676d3c44e7e841a6b6853f8d6db",
        "deepnote_cell_type": "markdown",
        "id": "MwE8yNg58VQN"
      },
      "source": [
        "## How will this notebook be Graded?\n",
        "\n",
        "If you are enrolled in the class, this notebook will be graded using [Gradescope](www.gradescope.com). You should have gotten the enrollement code on our announcement in Piazza. \n",
        "\n",
        "For submission of this assignment, you must do two things. \n",
        "- Download and submit the notebook `grasp_candidate.ipynb` to Gradescope's notebook submission section, along with your notebook for the other problems.\n",
        "\n",
        "We will evaluate the local functions in the notebook to see if the function behaves as we have expected. For this exercise, the rubric is as follows:\n",
        "- [4 pts] `compute_darboux_frame` must be implemented correctly.\n",
        "- [4 pts] `find_minimum_distance` must be implemented correctly.\n",
        "- [4 pts] `compute_candidate_grasps` must be implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "cell_id": "60c92bd49e2e4498bded65b9bdb314b7",
        "deepnote_cell_type": "code",
        "id": "xj5nAh4g8VQO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total score is 4/12.\n",
            "\n",
            "Score for Test compute_candidate_grasps is 0/4.\n",
            "- Test Failed: False is not true : Length of returned array is not correct.\n",
            "\n",
            "\n",
            "Score for Test compute_darboux_frame is 4/4.\n",
            "\n",
            "Score for Test find_minimum_distance is 0/4.\n",
            "- Test Failed: 'Timed Out'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from manipulation.exercises.clutter.test_grasp_candidate import TestGraspCandidate\n",
        "from manipulation.exercises.grader import Grader\n",
        "\n",
        "Grader.grade_output([TestGraspCandidate], [locals()], \"results.json\")\n",
        "Grader.print_test_results(\"results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a9f4175d-ea21-49c3-83c9-e5c3a0936239' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "035ca0d94e0e494b83f49836875b332e",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
