{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "8d81e6654aac4797af5b53ab0d1e7281",
        "deepnote_cell_type": "markdown",
        "id": "9CagYlhclDR4"
      },
      "source": [
        "# Normal Estimation from Depth Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "cell_id": "a575fddfa6c041c4b2efe1aa5467179c",
        "deepnote_cell_type": "code",
        "id": "_GMCWQ1RjBoB"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.patches import Rectangle\n",
        "from pydrake.all import RigidTransform, RotationMatrix, StartMeshcat\n",
        "\n",
        "from manipulation import running_as_notebook\n",
        "from manipulation.meshcat_utils import AddMeshcatTriad\n",
        "from manipulation.mustard_depth_camera_example import MustardExampleSystem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "cell_id": "a3a25a104e284c63ba0ebd66466d6b91",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:drake:Meshcat listening for connections at http://localhost:7002\n"
          ]
        }
      ],
      "source": [
        "# Start the visualizer.\n",
        "meshcat = StartMeshcat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f7f5a0c41d7e4d17a7ae83e8053326f5",
        "deepnote_cell_type": "markdown",
        "id": "UxATaRk3jBoH"
      },
      "source": [
        "# Problem Description\n",
        "In the lecture, we learned about estimating the point cloud normal vectors and surface curvations. For this exercise, you will investigate a slightly different approach. In particular, you will exploit the structure already presented in a depth image to avoid computing nearest neighbors. \n",
        "\n",
        "**These are the main steps of the exercise:**\n",
        "1. Implement the `estimate_normal_by_nearest_pixels` method.\n",
        "2. Come up with an example that breaks the `estimate_normal_by_nearest_pixels` method.\n",
        "\n",
        "Run the cell below to set up the simulation environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "cell_id": "85d4bee2a62b419aa3472f715a92d966",
        "deepnote_cell_type": "code",
        "id": "STaJPvHmjBoH"
      },
      "outputs": [],
      "source": [
        "class NormalEstimation:\n",
        "    def __init__(self):\n",
        "        diagram = MustardExampleSystem()\n",
        "        context = diagram.CreateDefaultContext()\n",
        "\n",
        "        # setup\n",
        "        meshcat.SetProperty(\"/Background\", \"visible\", False)\n",
        "\n",
        "        # getting data\n",
        "        self.point_cloud = diagram.GetOutputPort(\"camera0_point_cloud\").Eval(context)\n",
        "        self.rgb_im = diagram.GetOutputPort(\"camera0_rgb_image\").Eval(context).data\n",
        "        self.depth_im_read = (\n",
        "            diagram.GetOutputPort(\"camera0_depth_image\").Eval(context).data.squeeze()\n",
        "        )\n",
        "        self.depth_im = deepcopy(self.depth_im_read)\n",
        "        self.depth_im[self.depth_im == np.inf] = 10.0\n",
        "        label_im = (\n",
        "            diagram.GetOutputPort(\"camera0_label_image\").Eval(context).data.squeeze()\n",
        "        )\n",
        "        self.mask = label_im == 1\n",
        "\n",
        "        # camera specs\n",
        "        cam0 = diagram.GetSubsystemByName(\"camera0\")\n",
        "        cam0_context = cam0.GetMyMutableContextFromRoot(context)\n",
        "        self.X_WC = cam0.body_pose_in_world_output_port().Eval(cam0_context)\n",
        "        self.cam_info = cam0.depth_camera_info()\n",
        "\n",
        "    def project_depth_to_pC(self, depth_pixel, uv=None):\n",
        "        \"\"\"\n",
        "        project depth pixels to points in camera frame\n",
        "        using pinhole camera model\n",
        "        Input:\n",
        "            depth_pixels: numpy array of (nx3) or (3,)\n",
        "        Output:\n",
        "            pC: 3D point in camera frame, numpy array of (nx3)\n",
        "        \"\"\"\n",
        "        # switch u,v due to python convention\n",
        "        v = depth_pixel[:, 0]\n",
        "        u = depth_pixel[:, 1]\n",
        "        Z = depth_pixel[:, 2]\n",
        "        # read camera intrinsics\n",
        "        cx = self.cam_info.center_x()\n",
        "        cy = self.cam_info.center_y()\n",
        "        fx = self.cam_info.focal_x()\n",
        "        fy = self.cam_info.focal_y()\n",
        "        X = (u - cx) * Z / fx\n",
        "        Y = (v - cy) * Z / fy\n",
        "        pC = np.c_[X, Y, Z]\n",
        "        return pC\n",
        "\n",
        "    def plot_scanning_window(self, u_range, v_range):\n",
        "        \"\"\"\n",
        "        visualize the scanning window\n",
        "        u_range: (u_start, u_end)\n",
        "        v_range: (v_start, v_end)\n",
        "        u, v are the 1st and 2nd axis of the image array\n",
        "        \"\"\"\n",
        "        # switch u, v range to get x, y\n",
        "        x0, x1 = v_range\n",
        "        y0, y1 = u_range\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.imshow(self.depth_im)\n",
        "        ax.add_patch(Rectangle((x0, y0), x1 - x0, y1 - y0, alpha=0.5, fc=\"r\"))\n",
        "\n",
        "    def vis_normals(self, normals):\n",
        "        \"\"\" \"\"\"\n",
        "        for i in range(len(normals)):\n",
        "            name = \"normal_vec_{}\".format(i)\n",
        "            AddMeshcatTriad(meshcat, name, length=0.01, radius=0.001, X_PT=normals[i])\n",
        "\n",
        "\n",
        "def bbox(img):\n",
        "    a = np.where(img != 0)\n",
        "    bbox = ([np.min(a[0]), np.max(a[0])], [np.min(a[1]), np.max(a[1])])\n",
        "    return bbox\n",
        "\n",
        "\n",
        "env = NormalEstimation()\n",
        "mask = env.mask\n",
        "depth_im = env.depth_im"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3a777c21bf684599b298b01e69e2e1be",
        "deepnote_cell_type": "markdown",
        "id": "SevGI1izjBoN"
      },
      "source": [
        "The object of interest is the mustard bottle. Our goal in this exercise is to compute the estimate of point cloud normals of the mustard bottle from a depth image. The depth image is visualized below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "cell_id": "dbd67d1ccb1d40128e69249f7b4dc93b",
        "deepnote_cell_type": "code",
        "id": "TyACO5ThjBoO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x149542d50>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(depth_im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3759b150cad64548af504593a57b7829",
        "deepnote_cell_type": "markdown",
        "id": "yDpgse_ojBoS"
      },
      "source": [
        "The core idea of the approach is to exploit the fact that a depth image already includes spatial information among pixels. For example, for a selected pixel, the pixels that surround it are likely to be its nearest neighbors. Therefore, instead of computing nearest neighbors, we can instead use the nearest pixels in place of nearest neighbors. \n",
        "\n",
        "The cell below provides a sequence of screenshots of the method, where a square/rectangular window moves across the depth image. All pixels in the sliding window is used to compute the normal vector of the center point of the window. In your implementation below, you will use a smaller window and a smaller step size to get better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "3d27f62669824b019011f8897c1b7ed9",
        "deepnote_cell_type": "code",
        "id": "WD7U95EDjBoT"
      },
      "outputs": [],
      "source": [
        "uv_step = 40\n",
        "v_bound, u_bound = bbox(mask)\n",
        "\n",
        "for v in range(v_bound[0], v_bound[1], uv_step):\n",
        "    for u in range(u_bound[0], u_bound[1], uv_step):\n",
        "        center = [v, u]\n",
        "        u_length = 30\n",
        "        v_length = 30\n",
        "        if running_as_notebook:\n",
        "            env.plot_scanning_window(\n",
        "                [center[0] - v_length, center[0] + v_length + 1],\n",
        "                [center[1] - u_length, center[1] + u_length + 1],\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "458f27e452c24bd38a50405a2dee8cb6",
        "deepnote_cell_type": "markdown",
        "id": "o-8vPWxdjBoX"
      },
      "source": [
        "## Mapping Depth Image to Point Cloud\n",
        "\n",
        "Note that pixel indices of a depth image is not a valid position measurement in the 3D world. Fortunately, there is a simple mapping from pixel locations to poses in the 3D world, and it is called the [pinhole camera model](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html). We have helped you map all pixels of the depth image to points in the camera frame in the cell below. In case you need to gain direct access to this mapping, please refer to the `project_depth_to_pC` method in the `NormalEstimation` class.\n",
        "\n",
        "The diagram below is found from [OpenCV documentation](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html). Note that the $u$ and $v$ directions are reversed in Python due to the difference in convention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fcc30b2e2aee4eeea393c7dd609a721b",
        "deepnote_cell_type": "markdown",
        "id": "OaXlVRcskbDf"
      },
      "source": [
        "![](https://docs.opencv.org/3.4/pinhole_camera_model.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "cell_id": "e73222f84e35480c86ac18c34098e084",
        "deepnote_cell_type": "code",
        "id": "JHn2SKHDjBoY"
      },
      "outputs": [],
      "source": [
        "img_h, img_w = depth_im.shape\n",
        "v_range = np.arange(img_h)\n",
        "u_range = np.arange(img_w)\n",
        "depth_u, depth_v = np.meshgrid(u_range, v_range)\n",
        "depth_pnts = np.dstack([depth_v, depth_u, depth_im])\n",
        "depth_pnts = depth_pnts.reshape([img_h * img_w, 3])\n",
        "# point poses in camera frame\n",
        "pC = env.project_depth_to_pC(depth_pnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "44b2ec7f35274d83a29c79c8a87fd0bb",
        "deepnote_cell_type": "markdown",
        "id": "StDSt_MtjBoc"
      },
      "source": [
        "## Computing Surface Normals by Nearest Pixels\n",
        "Now we should be able to calculate the surface normals. Recall from section 5.5.2 of the textbook, in each sliding window we can use the points to construct a data matrix (also known as a *scatter matrix*) **W** which exhibits special properties that allows us to estimate the local normals. \n",
        "\n",
        "**Problem 5.2.a** [2pts] Which eigenvector of **W** corresponds to the vector normal to the points in the sliding window? Assume we want to specify a normal frame whose z-axis corresponds to the vector normal to the points in the sliding window. How can you use the eigenvectors of **W** to create a rotation matrix representing the desired orientation of the normal frame. Justify that your answer represents a valid rotation matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5.2 a: The eigenvector corresponding to the largest eigenvalue of the data matrix corresponds to the direction of least curvature. To find the desired rotation of the normal frame, we set up and solve for the following equation. $$V^TSV = D$$ The matrix $S$ is the matrix rotating from the camera frame to the normal frame.\n",
        "To justify that $S$ is a valid rotation matrix, we can take $det(S)$ and make sure the value is 1. Since W is symmetric, it produces orthogonal eigenvectors (from the notes). We are multiplying two orthogonal matrices to produce S."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "2878e1dc963147e6958fe573ab187973",
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "**Problem 5.2.b** [4pts] **Complete the implementation of the `estimate_normal_by_nearest_pixels` below.** \n",
        "\n",
        "Note that locations of sliding windows are provided to you for the ease of grading. The pose of the depth camera is `X_WC`, **it is a different depth camera from the one shown in the meshcat visualizer**. Lastly, **make sure the +z axis of the normal frame points outward, toward the depth camera (different from the one shown in the meshcat visualizer)**. It will be useful to review section 5.5.2 in the notes for computing the normal estimate. \n",
        "\n",
        "HINT: consider using *np.linalg.eigh*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "cell_id": "34fdd7c11eaa49bf8d3d4771cb39582b",
        "deepnote_cell_type": "code",
        "id": "arTPxyRMjBod"
      },
      "outputs": [],
      "source": [
        "X_WC = env.X_WC\n",
        "\n",
        "\n",
        "def estimate_normal_by_nearest_pixels(X_WC, pC, uv_step=10):\n",
        "    \"\"\"\n",
        "    compute the surface normals from the nearest pixels (by a sliding window)\n",
        "    Input:\n",
        "        X_WC: RigidTransform of the camera in world frame\n",
        "        pC: 3D points computed from the depth image in the camera frame\n",
        "        uv_step: recommended step size for the sliding window (see codes below)\n",
        "    Output:\n",
        "        normals: a list of RigidTransforms of the normal frames in world frame.\n",
        "                 The +z axis of the normal frame is the normal vector, it should\n",
        "                 points outward (towards the camera)\n",
        "    \"\"\"\n",
        "    normals = []\n",
        "    v_bound, u_bound = bbox(mask)\n",
        "    pC = pC.reshape(img_h, img_w, 3)\n",
        "    p_WC = X_WC.translation()\n",
        "    for v in range(v_bound[0], v_bound[1], uv_step):\n",
        "        for u in range(u_bound[0], u_bound[1], uv_step):\n",
        "            # v = 178 # DEBUG\n",
        "            # u = 325 # DEBUG\n",
        "            # center of the window at depth_im[u,v]\n",
        "            center = [v, u]\n",
        "            u_length = 3\n",
        "            v_length = 3\n",
        "            # side of the window\n",
        "            v_range = np.arange(max(v - v_length, 0), min(v + v_length + 1, img_h - 1))\n",
        "            u_range = np.arange(max(u - u_length, 0), min(u + u_length + 1, img_w - 1))\n",
        "\n",
        "            ### my code here\n",
        "\n",
        "            # pC_window is the 49 points in the window and their depth values\n",
        "            pC_window = pC[v_range, :, :][:, u_range, :].reshape(-1, 3) # list of 49 points with xyz coordinates in the window\n",
        "\n",
        "            # Perform PCA\n",
        "            pstar_C = np.mean(pC_window, axis=0)\n",
        "            prel_C = pC_window - pstar_C\n",
        "            W = np.matmul(prel_C.T, prel_C)\n",
        "            w, V = np.linalg.eigh(W) # eigh sorts the return values in ascending order\n",
        "\n",
        "            # The normal vector is the eigenvector corresponding to the smallest eigenvalue\n",
        "            R = np.fliplr(V)\n",
        "\n",
        "            # Handle improper rotations\n",
        "            R = R @ np.diag([1, 1, np.linalg.det(R)])\n",
        "\n",
        "            normal = R[:,2]\n",
        "            normal_world = X_WC.rotation().multiply(normal)\n",
        "\n",
        "            # Ensure the normal vector points outward (toward the camera)\n",
        "            if ((p_WC - X_WC.multiply(pstar_C)).dot(normal_world)) < 0:\n",
        "                R = R @ np.diag([1, -1, -1])\n",
        "            \n",
        "            # Transform from camera to world frame using X_WC\n",
        "            pstar_W = X_WC.multiply(pstar_C)\n",
        "\n",
        "            # mat = RotationMatrix(R)\n",
        "            mat = X_WC.rotation().multiply(RotationMatrix(R))\n",
        "\n",
        "            # Append the normal vector to the list\n",
        "            normals.append(RigidTransform(RotationMatrix(mat), pstar_W))\n",
        "\n",
        "    return normals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "cell_id": "c25bb3f7d9cc4fb1bc72da2910f48e13",
        "deepnote_cell_type": "code",
        "id": "PD117pt0jBol"
      },
      "outputs": [],
      "source": [
        "meshcat.Delete()\n",
        "normals = estimate_normal_by_nearest_pixels(X_WC, pC)\n",
        "env.vis_normals(normals)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c22ee9640904497abf2a158684171cc2",
        "deepnote_cell_type": "markdown",
        "id": "SfBjeNwmjBop"
      },
      "source": [
        "## Normal Vector Estimation with Noisy Depth\n",
        "\n",
        "\n",
        "The depth image tested in the first part of this exercise is a perfect depth image with no noise and missing values. Now imagine what will happen when noises and outliers are presented in the same depth image. \n",
        "\n",
        "**Problem 5.2.c** [2pts] **Illustrate a counter-example illustrating a case where the scanning window method cannot produce a good normal estimate.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "The algorithm doesn't work in any cases of occlusion or noise. The most obvious example of noise is discontinuities in the point cloud. Depth noise may produce sharp surface features in what might be an otherwise relatively flat surface, and this could shift the calculation of the normal by finding a local minimum in a \"pocket\" created by noisy depth data. Similarly, if the image is occluded or the shape has hidden concave surfaces, the normal vector estimation might have missing depth values that can mislead the algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "1ab6c9dc1df24b6ca820f6dda056c708",
        "deepnote_cell_type": "markdown",
        "id": "w-z5MD-PjBoq"
      },
      "source": [
        "## How will this notebook be Graded?\n",
        "\n",
        "If you are enrolled in the class, this notebook will be graded using [Gradescope](www.gradescope.com). You should have gotten the enrollement code on our announcement in Piazza. \n",
        "\n",
        "For submission of this assignment, you must do two things. \n",
        "- Download and submit the notebook `normal_estimation_depth.ipynb` to Gradescope's notebook submission section, along with your notebook for the other problems.\n",
        "- Answer 5.2.a and 5.2.c in the written section of Gradescope as a part of your `pdf` submission. \n",
        "\n",
        "We will evaluate the local functions in the notebook to see if the function behaves as we have expected. For this exercise, the rubric is as follows:\n",
        "- [2 pts] Identify which eigenvector of the data matrix W corresponds to the surface normal vector and explain how the eigenvectors can be used to compute the transform of the normal frame expressed in the camera frame.\n",
        "- [4 pts] `estimate_normal_by_nearest_pixels` must be implemented correctly. \n",
        "- [2 pts] Provide a reasonable scenario that breaks the `estimate_normal_by_nearest_pixels` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "cell_id": "01f0ce860eda47e49b271eefeffebe93",
        "deepnote_cell_type": "code",
        "id": "xWaeAZOwlz5-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total score is 4/4.\n",
            "\n",
            "Score for Testing the normal vectors is 4/4.\n"
          ]
        }
      ],
      "source": [
        "from manipulation.exercises.clutter.test_normal import TestNormal\n",
        "from manipulation.exercises.grader import Grader\n",
        "\n",
        "Grader.grade_output([TestNormal], [locals()], \"results.json\")\n",
        "Grader.print_test_results(\"results.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      },
      "source": [
        "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a9f4175d-ea21-49c3-83c9-e5c3a0936239' target=\"_blank\">\n",
        "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
        "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
      ]
    }
  ],
  "metadata": {
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "bb8ab8fc236546c0b87feb9fefd7ef9d",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
