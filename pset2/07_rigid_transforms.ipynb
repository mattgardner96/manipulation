{"cells":[{"cell_type":"markdown","metadata":{"id":"c9GoM16F7I7Z","colab_type":"text","cell_id":"e71a890799854a579aeafe89fbf16117","deepnote_cell_type":"markdown"},"source":"# Exercises on Rigid Transforms","block_group":"36fe41c699e74dfe963298f11e19d06d"},{"cell_type":"code","metadata":{"id":"xyZz8R16E9jZ","colab":{},"colab_type":"code","source_hash":"c8c1b969","execution_start":1726537913225,"execution_millis":6706,"deepnote_to_be_reexecuted":false,"cell_id":"17bb1fc1df3b465299a79080b3cebccb","deepnote_cell_type":"code"},"source":"# python libraries\nimport numpy as np\nfrom pydrake.all import RigidTransform, RotationMatrix\n\n# !pip install --no-cache-dir --ignore-installed manipulation==2024.9.12","block_group":"6697d7b340e84dfe8b086b08eb1416e4","execution_count":1,"outputs":[{"name":"stdout","text":"Collecting manipulation==2024.9.12\n  Downloading manipulation-2024.9.12-py3-none-any.whl (691 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.7/691.7 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting timeout-decorator>=0.4.1\n  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting trimesh[recommend]<4.2.0,>=4.0.0\n  Downloading trimesh-4.1.8-py3-none-any.whl (690 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m690.6/690.6 KB\u001b[0m \u001b[31m421.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tqdm>=4\n  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m425.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting vhacdx>=0.0.5\n  Downloading vhacdx-0.0.8.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.0/211.0 KB\u001b[0m \u001b[31m525.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nevergrad>=0.4.3\n  Downloading nevergrad-1.0.4-py3-none-any.whl (490 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.3/490.3 KB\u001b[0m \u001b[31m305.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting stable-baselines3>=2.0.0\n  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 KB\u001b[0m \u001b[31m500.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cloudpickle==2.2.1\n  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\nCollecting ipywidgets>=8\n  Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 KB\u001b[0m \u001b[31m473.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting gradescope-utils>=0.4.0\n  Downloading gradescope_utils-0.5.0-py2.py3-none-any.whl (7.1 kB)\nCollecting psutil>=5.9\n  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 KB\u001b[0m \u001b[31m285.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torchvision>=0.10.1\n  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m186.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch<2.4.0,>=2.0.1\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m240.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/75cd87da-797e-419c-8eb6-8278591b66b8","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"EvOQi_xQE9kY","colab_type":"text","cell_id":"7781122deb624366b571191a3379553d","deepnote_cell_type":"markdown"},"source":"# Problem Description\nIn the lecture, we learned the basics of spatial transformations. In this exercise, you will compute simple rigid transforms applying the rules you have learned in class.\n\n**These are the main steps of the exercise:**\n1. Compute rigid transforms of frames in various reference frames.\n2. Design grasp pose using spatial transformation","block_group":"905f15c59b094865891c9639dae879f0"},{"cell_type":"markdown","metadata":{"id":"L-1Ad6xYQ2aK","colab_type":"text","cell_id":"a19752941ae24a4f84979cfa4e313baa","deepnote_cell_type":"markdown"},"source":"# Exercise on Rigid Transforms\n\nAs a brief review, we have covered two rules of spatial transformation in [class](http://manipulation.csail.mit.edu/pick.html#spatial_algebra).\n\n$${^AX^B} {^BX^C} = {^AX^C},$$\n\n$$[^AX^B]^{-1} = {^BX^A}.$$\n\nNote that the rules of transforms are based on rules of transforming positions and rotations listed below. \n\nAddition of positions in the same frame:\n$$^Ap^B_F + ^Bp^C_F = ^Ap^C_F.$$\n\nThe additive inverse:\n$$^Ap^B_F = - ^Bp^A_F.$$\n\nRotation of a point:\n$$^Ap^B_G = {^GR^F} ^Ap^B_F.$$\n\nChaining rotations:\n$${^AR^B} {^BR^C} = {^AR^C}.$$\n\nInverse of rotations:\n$$[^AR^B]^{-1} = {^BR^A}.$$\n      \nApplying these rules will yield the same result as the ones computed by the former two rules.\n\nIn Drake, you can multiply frames by \n```python\nX_AB.multiply(X_BC)\nX_AB @ X_BC\n```\n\nYou may also inverse a rigid transform by the [inverse](https://drake.mit.edu/pydrake/pydrake.math.html?highlight=rigidtransform#pydrake.math.RigidTransform.inverse) method.\n\n```python\nX_AB.inverse()\n```","block_group":"cd638e8fae0b4245aa74020613707041"},{"cell_type":"markdown","metadata":{"id":"Ceqhp3vWZpzx","colab_type":"text","cell_id":"c697b85de62e4908adbfcadf3eb83d72","deepnote_cell_type":"markdown"},"source":"Now suppose you have 4 frames, namely, the world frame, frame A, frame B, and frame C defined as below.\n\n-- frame A expressed in the world frame (`X_WA`)\n\n-- frame B expressed in frame A (`X_AB`)\n\n-- frame B expressed in frame C (`X_CB`)\n\n**Calcuate the following transforms by filling your code below in the designated functions.**\n\n(1) `X_WB`, frame B expressed in the world frame\n\n(2) `X_CW`, the world frame expressed in frame C","block_group":"75fdd4b25d7f4226a323d44de760794b"},{"cell_type":"code","metadata":{"id":"FDPul5bRZpzy","colab":{},"colab_type":"code","source_hash":"d693f3e3","execution_start":1726538058801,"execution_millis":95,"deepnote_to_be_reexecuted":false,"cell_id":"78dd6e3e3dc34f11b683b54e31afc225","deepnote_cell_type":"code"},"source":"def compute_X_WB(X_WA, X_AB, X_CB):\n    \"\"\"\n    fill your code here\n    \"\"\"\n    X_WB = RigidTransform()\n    X_WB = X_WA @ X_AB\n\n    return X_WB","block_group":"e1e35d28587f40bd9d0b4af7f2439bf9","execution_count":19,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"xJQ1vThXZpz6","colab":{},"colab_type":"code","source_hash":"7d9bc204","execution_start":1726538059023,"execution_millis":77,"deepnote_to_be_reexecuted":false,"cell_id":"b753d6f5ed074cc2b1c675469de67de7","deepnote_cell_type":"code"},"source":"def compute_X_CW(X_WA, X_AB, X_CB):\n    \"\"\"\n    fill your code here\n    \"\"\"\n    X_CW = RigidTransform()\n    X_CW = (X_WA @ X_AB @ X_CB.inverse()).inverse()\n\n    return X_CW","block_group":"9ce1c14fde604a95bc7ddcd01e88a555","execution_count":20,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"3DJxbaN6wjMw","colab_type":"text","cell_id":"74a74a56922c403dbac6e8c2da5c3a8c","deepnote_cell_type":"markdown"},"source":"# Design Grasp Pose\nThe grasp pose is commonly defined in the object frame so that the grasp pose ${^OX^G}$ is independent of the pose of the object. The grasp pose in the world frame can be computed by \n\n$${{^WX^G} = {}{^W}X^{O}} {^OX^G},$$\n\nwhere $W$ stands for the world frame and $G$ denotes the grasp frame, following the convention in the textbook. \n\nYou should notice from the visualization below that the gripper frame is different from the world frame. In particular, the +y axis of the gripper frame points vertically downward, and the +z axis of the gripper points backward. This is an important observation for this exercise.","block_group":"563387b9dca248d7af934d42b0b52170"},{"cell_type":"markdown","metadata":{"id":"o-5gZ-jPJJ-9","colab_type":"text","cell_id":"cf07e6187817438a85643ff460e01987","deepnote_cell_type":"markdown"},"source":"**Now for your exercise, use the gripper and object's orientation from the image to design a grasp pose that satisfy the conditions below**\n\n- **gripper's position should be 0.02 unit distance above the target object in the world frame**\n- **gripper's z axis should align with object's x axis**\n- **gripper's x axis should align with object's z axis**\n- **write grasp pose in the object frame and the world frame**\n\n**Remember that the X-axis is shown in red, Y-axis is in green, and Z-axis in blue.**","block_group":"619c5d9883924320a18a52d6e870bd2e"},{"cell_type":"markdown","metadata":{"id":"txN1Mlk5MTjl","colab_type":"text","cell_id":"03712a829e6d4f0a96b814552ce56468","deepnote_cell_type":"markdown"},"source":"<img src=\"https://raw.githubusercontent.com/RussTedrake/manipulation/master/book/figures/exercises/grasp_pose_design.png\" width=\"500\">\n","block_group":"09567b978a8d45549a35ffb526a5f061"},{"cell_type":"code","metadata":{"id":"ju-etoLzJ5zz","colab":{},"colab_type":"code","source_hash":"e74a5e57","execution_start":1726539282814,"execution_millis":104,"deepnote_to_be_reexecuted":false,"cell_id":"d4065609d43c4feebc00e81a96c15fb9","deepnote_cell_type":"code"},"source":"# Establish the pose of the block expressed in the world frame as shown in the image above.\n\np0_WO = [0.5, 0.1, 0]  # object in world frame\nR0_WO = RotationMatrix.MakeZRotation(-np.pi / 2)\nR0_WO = R0_WO.multiply(RotationMatrix.MakeXRotation(np.pi / 2))\nX_WO = RigidTransform(R0_WO, p0_WO)","block_group":"34fb98b94bb74840b420090b8c6dbd47","execution_count":35,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"84Po2q-MOLcJ","colab":{},"colab_type":"code","source_hash":"5a84b789","execution_start":1726539328727,"execution_millis":36,"deepnote_to_be_reexecuted":false,"cell_id":"d05340c0c48e47918c38fed5cfb8d3b4","deepnote_cell_type":"code"},"source":"def design_grasp_pose(X_WO):\n    \"\"\"\n    fill in our code below\n    \"\"\"\n    # define the transform from the gripper frame to the \n    # X_OG is the desired position of the gripper relative to the object\n    # \n\n    X_OG = RigidTransform()\n    p_OG = [0,0.02,0]\n    R_OG = RotationMatrix.MakeZRotation(np.pi)\n    R_OG = R_OG.multiply(RotationMatrix.MakeYRotation(-np.pi/2))\n    X_OG = RigidTransform(R_OG, p_OG)\n\n    X_WG = RigidTransform()\n    X_WG = X_WO @ X_OG\n    return X_OG, X_WG","block_group":"a8ae9de3882d4bc9a20f8993154b479e","execution_count":40,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"zPmeRLtJk410","colab_type":"text","cell_id":"383d2ea3b6b546dea4fabf29efa84c01","deepnote_cell_type":"markdown"},"source":"## How will this notebook be Graded?\n\nIf you are enrolled in the class, this notebook will be graded using [Gradescope](www.gradescope.com). You should have gotten the enrollement code on our announcement in Piazza. \n\nFor submission of this assignment, you must do two things. \n- Download and submit the notebook `rigid_transforms.ipynb` to Gradescope's notebook submission section, along with your notebook for the other problems.\n\nWe will evaluate the local functions in the notebook to see if the function behaves as we have expected. For this exercise, the rubric is as follows:\n- [1 pts] `compute_X_WB` is correct\n- [1 pts] `compute_X_CW` is correct\n- [2 pts] `design_grasp_pose` is correct according to the requirement","block_group":"f3aa9c42d739420e90e06a71ea4cb183"},{"cell_type":"code","metadata":{"id":"T2PwWuqT_O3r","colab":{},"colab_type":"code","source_hash":"7d04f91","execution_start":1726539330055,"execution_millis":224,"deepnote_to_be_reexecuted":false,"cell_id":"fac471fef70d4f4d91bf5787f86cbf6b","deepnote_cell_type":"code"},"source":"from manipulation.exercises.grader import Grader\nfrom manipulation.exercises.pick.test_rigid_transforms import TestRigidTransforms\n\nGrader.grade_output([TestRigidTransforms], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")","block_group":"6ceec65996c04f61a3af3696a4e01e0b","execution_count":41,"outputs":[{"name":"stdout","text":"Total score is 4/4.\n\nScore for Testing X_CW is 1/1.\n\nScore for Testing X_WB is 1/1.\n\nScore for Testing grasp pose is 2/2.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/e7ad2f37-397c-489b-a288-b68a8c7ae5d6","content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"9c118fb2813045c5a63d5a5d6f8fe388","deepnote_cell_type":"code"},"source":"","block_group":"a39431206a314541828bab50e913c24f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=4a35a9f3-a2a1-4022-9c03-4fb430e99463' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"2ce535feff4e458e9da4c6d58109f5df","deepnote_execution_queue":[]}}